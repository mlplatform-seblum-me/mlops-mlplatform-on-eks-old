airflow:
  config:
    AIRFLOW__WEBSERVER__EXPOSE_CONFIG: "True"

    #AIRFLOW__CORE__REMOTE_LOGGING : True
    # AIRFLOW__SCHEDULER__DAG_DIR_LIST_INTERVAL: 30.0
    AIRFLOW__LOGGING__LOGGING_LEVEL: "DEBUG" 
    AIRFLOW__LOGGING__REMOTE_LOGGING: "True"
    AIRFLOW__LOGGING__REMOTE_BASE_LOG_FOLDER: "s3://airflowdatabucket/airflow/logs"
    AIRFLOW__LOGGING__REMOTE_LOG_CONN_ID: "aws_logs_storage_access"

    # AIRFLOW__CORE__DAGBAG_IMPORT_TIMEOUT: "30.0"
    AIRFLOW__CORE__DEFAULT_TIMEZONE: Europe/Amsterdam
    # AIRFLOW__KUBERNETES_EXECUTOR__NAMESPACE: "airflow"
    # AIRFLOW__KUBERNETES__WORKER_SERVICE_ACCOUNT_NAME: "airflow-sa"
    # AIRFLOW__KUBERNETES__FS_GROUP: "65534"
  users:
    ## define the user called "admin"  # TODO
    - username: admin
      password: admin
      role: Admin
      email: admin@example.com
      firstName: admin
      lastName: admin
    ## define the user called "user"  # TODO
    - username: user
      password: user123
      role:
        - User
        - Viewer
      email: user@example.com
      firstName: user
      lastName: user
  image:
    repository: seblum/airflow # auslagers
    tag: 2.6.2-python3.11-custom # auslagers
    pullPolicy: IfNotPresent
    pullSecret: ""
    uid: 50000
    gid: 0
  executor: KubernetesExecutor # auslagern?
  fernetKey: "7T512UXSSmBOkpWimFHIVb8jK6lfmSAvx4mO6Arehnc=" # auslagern?
  webserverSecretKey: "THIS IS UNSAFE!"
  # kubernetesPodTemplate:
  #   stringOverride: |-
  #serviceAccountName: "airflow-sa"


  connections:
    - id: aws_logs_storage_access
      type: aws
      description: AWS connection to store logs on S3
      extra: |-
        {
          "region_name": "eu-central-1"
        }
  variables:
    - key: "MLFLOW_TRACKING_URI"
      value: "http://mlflow-service.mlflow.svc.cluster.local"
    - key: "s3_access_name"
      value: "airflow-s3-data-bucket-access-credentials"
serviceAccount:
  create: true
  name: "airflow-sa"
  annotations:
    eks.amazonaws.com/role-arn: "arn:aws:iam::855372857567:role/testrolle"

workers:
  enabled: false
flower:
  enabled: false
postgresql:
  enabled: false
redis:
  enabled: false
externalDatabase:
  type: postgres
  host: ""
  port: ""
  database: airflow_db # auslagern?
  user: airflow_admin # auslagern?
  passwordSecret: ""
  passwordSecretKey: "postgresql-password" # auslagern?
  properties: ""
scheduler:
  replicas: 1
dags:
  gitSync:
    enabled: true
    repo: ""
    branch: ""
    revision: HEAD
    repoSubPath: "dags"
    httpSecret: ""
    httpSecretUsernameKey: username # auslagern?
    httpSecretPasswordKey: password # auslagern?
    syncWait: 60 # default
    syncTimeout: 120 # default
# web:
#   replicas: 1
#   service:
#     annotations:
#       app: airflow
#       component: web
#     type: LoadBalancer
